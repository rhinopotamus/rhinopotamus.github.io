<?xml version="1.0" encoding="UTF-8" ?>

<!--********************************************************************
Copyright 2015 Robert A. Beezer

This file is part of MathBook XML.

MathBook XML is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 2 or version 3 of the
License (at your option).

MathBook XML is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with MathBook XML.  If not, see <http://www.gnu.org/licenses/>.
*********************************************************************-->
<!-- This file was originally part of the book     -->
<!-- (as copied on 2015/07/12)                     -->
<!--                                               -->
<!--   Abstract Algebra: Theory and Applications   -->
<!--                                               -->
<!-- Copyright (C) 1997-2014  Thomas W. Judson     -->

<chapter xml:id="shortest" xmlns:xi="http://www.w3.org/2001/XInclude">


<title>Shortest Distances</title>

  <section xml:id="sec-shortest-arc">
    <title>The shortest arc joining two points</title>

    <p> Problems of determining shortest distances furnish a useful elementary introduction to the theory of the calculus of variations because the properties characterizing their solutions are familiar ones which illustrate very well many of the general principles common to all of the problems suggested in the preceding chapter. If we can for the moment eradicate from our minds all that we know about straight lines and shortest distances we shall have the pleasure of rediscovering well-known theorems by methods which will be helpful in solving more complicated problems. </p>

    <!-- TODO: Update reference-->
    <p>Let us begin with the simplest case of all, the problem of determining the shortest arc joining two given points. The integral to be minimized, which we have already seen on page 6 of the preceding chapter, may be written in the form
    <men xml:id="eqn-shortest">
      I=\int_{x_1}^{x_2} f(y')\,dx
    </men>
    if we use the notation <m>f(y')=\sqrt{1+(y')^2}</m>, and the arcs <m>y=y(x)\,\,(x_1\leq x\leq x_2)</m> whose lengths are to be compared with each other will always be understood to be continuous and to consist of a finite number of arcs on each of which the tangent turns continuously, as indicated in <xref ref="fig-piecewise-smooth"/>.</p> 

    <figure xml:id="fig-piecewise-smooth">
      <image source="images/fig-piecewise-smooth.png" >
        <description>A piecewise-smooth arc connecting points 1 and 2.</description>
      </image>
    </figure>
    
    <p>Analytically this means that on the interval <m>x_1\leq x\leq x_2</m> the function <m>y(x)</m> is continuous and that the interval can be subdivided into parts on each of which <m>y(x)</m> has a continuous derivative. Let us agree to call such functions <term>admissible functions</term> and the arcs which they define <term>admissible arcs</term>. Our problem is then to find among all admissible arcs joining two given points 1 and 2 one which makes the integral <m>I</m> a minimum. </p>

    <remark xml:id="remark-admissible">
      <title>Admissible arcs</title>
      <p>
        Other authors often refer to this condition as being <term>piecewise differentiable</term> or <term>piecewise smooth</term>: while an admissible function is allowed to have cusps where it isn't differentiable, you can chop it up into a number of <em>pieces</em> on which it is indeed differentiable.
      </p>
    
    </remark>

  </section>

  <section xml:id="sec-first-necessary">
    <title>A first necessary condition</title>
    
    <p>Let it be granted that a particular admissible arc <m>E_{12}</m> with the equation
    <me>
      y=y(x)\quad (x_1\leq x\leq x_2)
    </me>
    furnishes the solution of our problem, and let us then seek to find the properties which distinguish it from the other admissible arcs joining points 1 and 2. If we select arbitrarily an admissible function <m>\eta(x)</m> satisfying the conditions <m>\eta(x_1) = \eta(x_2) = 0</m>, the equation 
    <men xml:id="eqn-variation">
      y=y(x)+a \eta(x)\quad (x_1\leq x\leq x_2),
    </men>

    involving the arbitrary constant <m>a</m>, represents a one-parameter family of curves which includes the arc <m>E_{12}</m> for the special value <m>a=0</m>, and all of the curves of the family pass through the end-points 1 and 2 of <m>E_{12}</m>.
    </p>

    <remark xml:id="remark-var-wiggle">
      <title>Variations and wiggles</title>
      <p>
        Admissible curves of the form given in <xref ref="eqn-variation"/> are called by other authors <term>variations</term> -- hence, the "calculus of variations". Think of them as starting with <m>y(x)</m> and "wiggling" it by <m>\eta(x)</m>. So, I'm going to define a <term>wiggle</term> as an admissible function <m>\eta(x)</m> that satisfies the conditions <m>\eta(x_1) = \eta(x_2) = 0</m>.
      </p>
      <p>
        We insist that <m>\eta(x_1) = \eta(x_2) = 0</m> so that the starting and ending points don't get wiggled away from where they're supposed to be, so that a variation is some other admissible arc joining points 1 and 2. You can "scale up" the amount of wiggle by multiplying <m>\eta(x)</m> by some constant <m>a</m>; note in particular that when <m>a=0</m>, there's zero wiggle, and so the variation <m>y(x)+a \eta(x)</m> is just the original function <m>y(x)</m>.
      </p>
      
    </remark>

    <p>
    The value of the integral <m>I</m> taken along an arc of the family depends upon the value of <m>a</m> and may be represented by the symbol
    <men xml:id="eqn-iofa">
      I(a)=\int_{x_1}^{x_2} f(y'+a \eta')\, dx.
    </men>
    Along the initial arc <m>E_{12}</m> the integral has the value <m>I(0)</m>, and if this is to be a minimum when compared with the values of the integral along all other admissible arcs joining 1 with 2 it must in particular be a minimum when compared with the values <m>I(a)</m> along the arcs of the family <xref ref="eqn-variation"/>.  Hence according to the criterion for a minimum of a function given on page 4 of the last chapter we must have <m>I'(0) = 0</m>.
    </p>

    <p>
    It should perhaps be emphasized here that the method of the calculus of variations, as it has been developed in the past, consists essentially of three parts; first, the deduction of necessary conditions which characterize a minimizing arc; second, the proof that these conditions, or others obtained from them by slight modifications, are sufficient to insure the minimum sought; and third, the search for an arc which satisfies the sufficient conditions. For the deduction of necessary conditions the value of the integral <m>I</m> along the minimizing arc can be compared with its values along any special admissible arcs which may be convenient for the purposes of the proof in question, for example along those of the family <xref ref="eqn-variation"/> described above, but the sufficiency proofs must be made with respect to all admissible arcs joining the points 1 and 2. The third part of the problem, the determination of an arc satisfying the sufficient conditions, is frequently the most difficult of all, and is the part for which fewest methods of a general character are known. For shortest-distance problems fortunately this determination is usually easy.
    </p>

    <activity xml:id="act-diff-under-int">
      <p>
        This next result is a doozy, and it uses an important technique with which you're probably not especially familiar: <term>differentiation under the integral sign</term>
        <fn>For more on this, see <url href="https://kconrad.math.uconn.edu/blurbs/analysis/diffunderint.pdf">this interesting article</url> and its references.</fn>. Here's a little activity to walk you through what's going on here.
        <ol>
          <li>
            <p>
              Convince yourself that <m>I(a)</m> as given in <xref ref="eqn-iofa"/> is indeed a function of <m>a</m>, and thus it's reasonable for us to compute <m>\frac{dI}{da}</m>. Also, convince yourself that <m>y'+a\eta'</m> is a function of both <m>x</m> and <m>a</m>.
            </p>
          </li>
          <li>
            <p>
              Here's where "differentiation under the integral sign" comes in: according to something called Leibniz's rule, as long as our functions are "nice enough" (which they are), 
              <me>
                \frac{d}{da} \int_{x_1}^{x_2} F(x, a)\, dx = \int_{x_1}^{x_2} \frac{\partial}{\partial a} F(x,a)\, dx.
              </me>
              Apply Leibniz's rule to write down an expression for <m>\frac{dI}{da}</m> in <xref ref="eqn-iofa"/>.
            </p>
            <solution>
              <me>
                \frac{d}{da} \int_{x_1}^{x_2} f(y'+a\eta')\, dx = \int_{x_1}^{x_2} \frac{\partial}{\partial a} f(y'+a\eta')\, dx.
              </me>
            </solution>
          </li>
          <li>
            <p>
              We're going to need the chain rule to deal with the integrand on the RHS. In particular, it'll be helpful for us to think about the chain rule in Leibniz notation (he's just popping up all over today!):
              <me>
                \frac{\partial f}{\partial a} = \frac{\partial f}{\partial u} \cdot \frac{\partial u}{\partial a}.
              </me>
              Explain why this version of the chain rule is equivalent to the usual understanding: "first take the derivative of the outside stuff, leaving the inside stuff alone, then multiply by the derivative of the inside stuff."
            </p>
          </li>
          <li>
            <p>
              What's something good you can label as <m>u</m> in your expression for <m>\frac{dI}{da}</m>? What's <m>\frac{\partial u}{\partial a}</m>, and so what's <m>\frac{\partial f}{\partial a}</m>?
            </p>
            <solution>
            <p>
              <m>u</m> should be the inside stuff, <m>u=y'+a\eta'</m>. Therefore, 
                <me>
                  \frac{\partial u}{\partial a} = \eta' \textrm{,  so  } \frac{\partial f}{\partial a} = \frac{\partial f}{\partial u}\cdot \eta'.
                </me>
            </p>
            </solution>
          </li>
          <li>
            <p>
              We mostly care about <m>I(a)</m> when <m>a=0</m> -- that is, when there's zero variation on the original curve <m>y(x)</m>. If <m>a=0</m>, then what's <m>u</m>? Use this to rewrite your integrand <m>\frac{\partial f}{\partial a}</m>.
            </p>
            <solution>
              <p>
                If <m>a=0</m>, then <m>u = y'+0\cdot\eta' = y'</m>. Therefore, we can rewrite our integrand to remove the convenience variable <m>u</m> that we kinda don't care about anyway:
                <me>
                  \frac{\partial f}{\partial a} = \frac{\partial f}{\partial u}\cdot \eta' = \frac{\partial f}{\partial y'}\cdot \eta'.
                </me>
              </p>
            </solution>
          </li>
          <li>
            <p>
              Conclude by writing down a final expression for <m>I'(0)</m>.
            </p>
            <solution>
              <me>
                I'(0) = \int_{x_1}^{x_2} \frac{\partial}{\partial y'}f(y') \cdot \eta'\, dx.
              </me>
              
            </solution>
          </li>
        </ol>
      </p>
    </activity>

    <p>
      By differentiating the expression <xref ref="eqn-iofa"/> with respect to <m>a</m> and then setting <m>a=0</m> the value of <m>I'(0)</m> is readily seen to be 
      <men xml:id="eqn-iprime0">
        I'(0) = \int_{x_1}^{x_2} f_{y'} \eta'\,dx,
      </men>
      where for convenience we use the notation <m>f_{y'}</m> for the derivative of the integrand <m>f(y')</m> with respect to <m>y'</m>. It will always be understood that the argument in <m>f</m> and its derivatives is the function <m>y'(x)</m> belonging to the arc <m>E_{12}</m> unless some other is expressly indicated, as is done, for example, in the formula <xref ref="eqn-iofa"/>.
    </p>

    <p>
      What now are the conclusions which can be drawn from the necessity of the condition <m>I'(0)=0</m>? The answer to this question is to be found in the lemma of the following section which will be frequently applied in later chapters as well as in the solution of the shortest-distance problems to which this chapter is devoted.
    </p>
  </section>

<section xml:id="sec-fundamental-lemma">
  <title>A fundamental lemma</title>
  
  <p>
     In the integrand of the integral <xref ref="eqn-iprime0"/> the coefficient of <m>\eta'</m> is really a function of <m>x</m>, since the derivative <m>f_{y'}</m> contains as its argument the slope <m>y'(x)</m> of the arc <m>E_{12}</m>, and we may denote this coefficient by <m>M(x)</m>. It should be noted that the function <m>M(x)</m> is continuous except possibly at the values of <m>x</m> defining the corners of the arc <m>E_{12}</m> where the slope <m>y'(x)</m> changes abruptly. At those points of the curve it has two values, one corresponding to the backward and one to the forward slope. The lemma which we wish to prove is then as follows:
  </p>
  <lemma xml:id="lemma-fundamental">
    <title>The Fundamental Lemma</title>
    <statement>
      <p>
        Let <m>M(x)</m> be a function of the kind described above, continuous on the interval <m>x_1\leq x \leq x_2</m>, or else such that the interval can be subdivided into a finite number of parts on each of which <m>M(x)</m> is continuous. If the integral
        <me>
          \int_{x_1}^{x_2} M(x)\eta'(x)\,dx
        </me>
        vanishes for every admissible function <m>\eta(x)</m> such that <m>\eta(x_1)=\eta(x_2)=0</m>, then <m>M(x)</m> is necessarily a constant.
      </p>
    </statement>
  </lemma>
  <remark xml:id="remark-fun-lemma">
    I want to restate this lemma just slightly so it's clearer what it's saying. Suppose that:
    <ul>
      <li>
        <p>
          <m>M(x)</m> is a piecewise-continuous function
        </p>
      </li>
      <li>
        <p>
          <m>\eta(x)</m> is a wiggle
        </p>
      </li>
      <li>
        <p>
          <m>\displaystyle \int_{x_1}^{x_2} M(x)\eta'(x)\,dx = 0</m>, <em>no matter which wiggle <m>\eta(x)</m> you choose!</em>
        </p>
      </li>
    </ul>
    Then we get to conclude that <m>M(x)</m> is in fact a constant function.
  </remark>
  <activity>
    Before we see the proof itself, let's build up to it by working through some of the trickier parts.
    <ol>
      <li>
        <p>
          Suppose <m>C</m> is just some constant, and remember that <m>\eta(x)</m> is supposed to be a wiggle in the sense of <xref ref="remark-var-wiggle"/>. Compute <m>\int_{x_1}^{x_2} C\cdot\eta'\,dx.</m>
        </p>
        <solution>
          <me>
            \int_{x_1}^{x_2} C\cdot\eta'\,dx = C \cdot \eta(x) \large\vert_{x_1}^{x_2} = C \cdot (\eta(x_2) - \eta(x_1)) = C\cdot(0-0) = 0.
          </me>
        </solution>
      </li>
      <li>
        <p>
          Consider the function <m>\displaystyle \eta^*(x) = \left(\int_{x_1}^x M(t)\,dt\right) - C\cdot(x-x_1)</m>. As you may suspect since I used the letter <m>\eta</m>, I'd really like it if <m>\eta^*(x)</m> was a wiggle. Compute <m>\eta^*(x_1)</m>.
        </p>
      </li>
      <li>
        <p>
          Is there a value of <m>C</m> (which is supposed to be a constant) such that <m>\eta^*(x_2)=0</m>? (Hint: <m>\int_{x_1}^{x_2} M(t)\,dt</m> is just some area or other.)
        </p>
      </li>
      <li>
        <p>
          Compute the derivative of this particular wiggle <m>\eta^*(x)</m>. (You'll need the fundamental theorem of calculus.)
        </p>
      </li>
      <li>
        <p>
          Finally, and changing gears a little, think of some function <m>f(x)</m>. What can you tell me about <m>\int_a^b \left[f(x)\right]^2\,dx</m>? Is it positive or negative? Can it ever be zero?
        </p>
      </li>
    </ol>
  </activity>
  <p>
    To see that this is so we note first that the vanishing of the integral of the lemma implies also the equation 
    <men xml:id="eqn-5">
      \int_{x_1}^{x_2} \left[M(x)-C\right]\eta'(x)\,dx = 0
    </men>
    for every constant <m>C</m>, since all the functions <m>\eta(x)</m> to be considered have <m>\eta(x_1)=\eta(x_2)=0</m>. The particular function <m>\eta(x)</m> defined by the equation 
    <men xml:id="eqn-6">
      \eta(x) = \int_{x_1}^x M(x)\,dx - C\cdot(x-x_1)
    </men>
    evidently has the value zero at <m>x=x_1</m> and it will vanish again at <m>x=x_2</m> if, as we shall suppose, <m>C</m> is the constant value satisfying the condition 
    <me>
      0=\int_{x_1}^{x_2} M(x)\,dx - C\cdot(x_2-x_1).
    </me>
    The function <m>\eta(x)</m> defined by <xref ref="eqn-6"/> with this value of <m>C</m> inserted is now one of those which must satisfy <xref ref="eqn-5"/>. Its derivative is <m>\eta'(x)=M(x)-C</m> except at points where <m>M(x)</m> is discontinuous, since the derivative of an integral with respect to its upper limit is the value of the integrand at that limit whenever the integrand is continuous at the limit. For the special function <m>\eta(x)</m>, therefore, <xref ref="eqn-5"/> takes the form 
    <me>
      \int_{x_1}^{x_2} \left[M(x)-C\right]^2\,dx =0
    </me>
    and our lemma is an immediate consequence since this equation can be true only if <m>M(x) \equiv C</m>.
  </p>

  
</section>

<section xml:id="sec-straight-line">
  <title>Proof that the straight line is shortest</title>
  <p>
    In the equation <m>y=y(x)+a\eta(x)</m> of the family of curves passing through the points 1 and 2 the function <m>\eta(x)</m> was entirely arbitrary except for the restrictions that it should be admissible and satisfy the relations <m>\eta(x_1)=\eta(x_2)=0</m>, and we have seen that the expression <xref ref="eqn-iprime0"/> for <m>I'(0)</m> must vanish for every such family. The lemma of the preceding section is therefore applicable and it tells us that along the minimizing arc <m>E_{12}</m> an equation
    <me>
      f_{y^{\prime}}=\frac{y^{\prime}}{\sqrt{1+y^{\prime 2}}}=C
    </me>
    must hold, where <m>C</m> is a constant. If we solve this equation for <m>y'</m> we see that <m>y'</m> is also a constant along <m>E_{12}</m> and that the only possible minimizing arc is therefore a single straight-line segment without corners joining the point 1 with the point 2.
  </p>
</section>

<section xml:id="sec-auxiliary-formulas">
  <title>Two important auxiliary formulas</title>
  
</section>
  
<section xml:id="sec-field">
  <title>The notion of a field and a second sufficiency proof</title>
  
</section>

<section xml:id="sec-shortest-curve">
  <title>The shortest arc joining a point to a curve</title>
  
</section>

<section xml:id="sec-shortest-ellipse">
  <title>The shortest arc joining a point to an ellipse</title>

</section>

<section xml:id="sec-two-curves">
  <title>The shortest arc joining two curves</title>
  
</section>
</chapter>
